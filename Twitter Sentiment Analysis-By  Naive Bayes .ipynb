{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Load Trainning and test data\n",
    "data_train=pd.read_csv('tweets_train.csv',encoding='latin-1')\n",
    "data_test=pd.read_csv('tweets_test.csv',encoding='latin-1')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99989 entries, 0 to 99988\n",
      "Data columns (total 3 columns):\n",
      "ItemID           99989 non-null int64\n",
      "Sentiment        99989 non-null int64\n",
      "SentimentText    99989 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "###Data Preprocessing\n",
    "##1.Check Null values\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.Tokenziation\n",
    "tokens=[]\n",
    "for word in data_train['SentimentText']:\n",
    "    tokens.append(word_tokenize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2.Data Cleaning-Remove stop word,special characters\n",
    "filtered_tokens=[]\n",
    "for w in tokens:\n",
    "    if w not in stopwords.words('english'):\n",
    "        filtered_tokens.append(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score,classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Split the data into Trainning and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(data_train['SentimentText'],data_train['Sentiment'],test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MultiNomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweety.t\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Counter Vectorizer and MutinomialNB--------------\n",
      "\n",
      "----------------Best Score of GridSearchcv -----------------\n",
      "0.7570436621328152\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "-----------------Best Parameters--------------------------------\n",
      "\n",
      "Best Parametrs: {'clf__alpha': 0.01, 'cv__max_df': 0.5, 'cv__max_features': 10000, 'cv__ngram_range': (1, 2)}\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "-----------------Best Test Score ---------------------\n",
      "0.7615761576157616\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "-----------------Classification Report-------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7199    0.7473    0.7333     13160\n",
      "           1     0.7964    0.7728    0.7844     16837\n",
      "\n",
      "   micro avg     0.7616    0.7616    0.7616     29997\n",
      "   macro avg     0.7582    0.7600    0.7589     29997\n",
      "weighted avg     0.7629    0.7616    0.7620     29997\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cv_pipln= Pipeline([('cv', CountVectorizer()),('clf', MultinomialNB())])\n",
    "cv_param_tune={\n",
    "    'cv__max_features':(None,1000,10000),\n",
    "    'cv__max_df':(0.5,0.7,1.0),\n",
    "    'cv__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'clf__alpha': (0.01, 0.001)\n",
    "}\n",
    "grid_cv=GridSearchCV(cv_pipln,cv_param_tune)\n",
    "grid_cv.fit(X_train,y_train)\n",
    "print(\"----------------Counter Vectorizer and MutinomialNB--------------\")\n",
    "print(\"\\n----------------Best Score of GridSearchcv -----------------\")\n",
    "print(grid_cv.best_score_)\n",
    "print(\"\\n---------------------------------------------------------------\")\n",
    "print(\"\\n-----------------Best Parameters--------------------------------\")\n",
    "print(\"\\nBest Parametrs:\",grid_cv.best_params_)\n",
    "print(\"\\n---------------------------------------------------------------\")\n",
    "print(\"\\n-----------------Best Test Score ---------------------\")\n",
    "print(grid_cv.best_estimator_.score(X_test,y_test))\n",
    "print(\"\\n---------------------------------------------------------------\")\n",
    "print(\"\\n-----------------Classification Report-------------------------\")\n",
    "print(classification_report(y_test, grid_cv.predict(X_test), digits=4))\n",
    "print(\"\\n---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweety.t\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tf_pipln= Pipeline([('tf', TfidfVectorizer()),('clf', MultinomialNB())])\n",
    "tf_param_tune={\n",
    "    'tf__max_features':(None,1000,10000),\n",
    "    'tf__min_df':(3,4),\n",
    "    'tf__max_df':(0.5,0.7,1.0),\n",
    "    'tf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'clf__alpha': (0.01, 0.001)\n",
    "    \n",
    "}\n",
    "grid_tf=GridSearchCV(tf_pipln,tf_param_tune)\n",
    "grid_tf.fit(X_train,y_train)\n",
    "print(\"----------------Tfidf Vectorizer and MutinomialNB--------------\")\n",
    "print(\"\\n----------------Best Score of GridSearchcv -----------------\")\n",
    "print(grid_tf.best_score_)\n",
    "print(\"\\n---------------------------------------------------------------\")\n",
    "print(\"\\n-----------------Best Parameters--------------------------------\")\n",
    "print(grid_tf.best_params_)\n",
    "print(\"\\n---------------------------------------------------------------\")\n",
    "print(\"\\n-----------------Best Test Score ---------------------\")\n",
    "print(grid_tf.best_estimator_.score(X_test,y_test))\n",
    "print(\"\\n---------------------------------------------------------------\")\n",
    "print(\"\\n-----------------Classification Report-------------------------\")\n",
    "print(classification_report(y_test, grid_tf.predict(X_test), digits=4))\n",
    "print(\"\\n---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
